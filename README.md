---
title: Automated ML Pipeline with CI/CD
emoji: ðŸ¤–
colorFrom: gray
colorTo: red
sdk: docker
app_file: Dockerfile
pinned: false
license: mit
---

# Under Construction

# Notes

Raw dataset: https://www.kaggle.com/datasets/harlfoxem/housesalesprediction

py -3.10 -m venv .venv

.\\.venv\Scripts\activate

python -m pip install --upgrade pip

pip install -r requirements-dev.txt

python scripts/bootstrap.py

uvicorn app.main:app --reload

# Automated ML Pipeline with CI/CD

[![License](https://img.shields.io/badge/license-MIT-blue)](LICENSE)

This repository contains a fully automated **Machine Learning pipeline** with **CI/CD capabilities**, designed for **house price prediction in King County, USA, 2015**. The project features reproducible model training, metric-based quality gates, versioned model packaging, and deployment-ready artifacts. It leverages **Python 3.10**, **scikit-learn**, **DVC**, and **GitHub Actions** for automation, ensuring enterprise-grade reproducibility and governance.

---

## Features

* **Automated Training & Evaluation:** Run training and evaluation pipelines with a single command.
* **Model Versioning:** Versioned models stored in a local registry (`models/registry`) with metadata.
* **Quality Gates:** Metric-based evaluation ensures only high-quality models are promoted.
* **Artifact Packaging:** Models packaged with metrics and metadata for reproducibility.
* **DVC Integration:** Track datasets, preprocessed data, and model artifacts.
* **CI/CD Pipelines:** Fully automated using GitHub Actions for testing, evaluation, and deployment.
* **Web Interface:** Minimal FastAPI dashboard for predictions.

---

## Repository Structure

```
Automated-ML-Pipeline-CI-CD-Clean/
â”œâ”€ .dvc/                   # DVC configuration and cache
â”‚  â”œâ”€ cache/               # DVC cache files
â”‚  â””â”€ tmp/                 # Temporary DVC files
â”œâ”€ .github/workflows/      # GitHub Actions workflows
â”‚  â”œâ”€ ml_pipeline.yml      # CI/CD pipeline workflow
â”‚  â””â”€ deploy_hf.yml        # Deployment to Hugging Face workflow
â”œâ”€ .vscode/                # VSCode workspace settings
â”œâ”€ app/                    # FastAPI application
â”‚  â”œâ”€ api/                 # API routes
â”‚  â”‚  â””â”€ routes.py
â”‚  â”œâ”€ core/                # Configs and logging
â”‚  â”‚  â”œâ”€ config.py
â”‚  â”‚  â””â”€ logging.py
â”‚  â”œâ”€ inference/           # Model inference logic
â”‚  â”‚  â””â”€ predictor.py
â”‚  â”œâ”€ schemas/             # Request/response schemas
â”‚  â”‚  â””â”€ request_response.py
â”‚  â”œâ”€ static/              # CSS and static assets
â”‚  â”‚  â””â”€ styles.css
â”‚  â”œâ”€ templates/           # HTML templates
â”‚  â”‚  â””â”€ index.html
â”‚  â””â”€ main.py              # FastAPI app entrypoint
â”œâ”€ data/                   # Data folder
â”‚  â”œâ”€ processed/           # Processed datasets (train/test split)
â”‚  â”‚  â””â”€ train_test.npz
â”‚  â”œâ”€ raw/                 # Raw datasets
â”‚  â”‚  â””â”€ kc_house_data.csv
â”‚  â””â”€ reference/           # Reference or lookup data
â”œâ”€ models/                 # Models and registry
â”‚  â”œâ”€ baseline/            # Baseline model and metrics
â”‚  â”œâ”€ packaged/            # Packaged model artifacts
â”‚  â””â”€ registry/            # Versioned model registry
â”‚     â”œâ”€ model_v001/
â”‚     â”œâ”€ model_v002/
â”‚     â”œâ”€ model_v003/
â”‚     â””â”€ latest.json       # Points to latest version
â”œâ”€ reports/                # Evaluation and comparison reports
â”‚  â”œâ”€ evaluations/         # Individual model evaluation JSON
â”‚  â””â”€ comparison.json      # Overall model comparison
â”œâ”€ scripts/                # Pipeline scripts
â”‚  â”œâ”€ bootstrap.py         # Initialize environment and dataset
â”‚  â”œâ”€ train.py             # Train a new model
â”‚  â”œâ”€ evaluate.py          # Evaluate a trained model
â”‚  â”œâ”€ compare.py           # Compare models and check quality gates
â”‚  â”œâ”€ metric_gate.py       # Metric gate logic
â”‚  â”œâ”€ package_model.py     # Package model artifacts
â”‚  â”œâ”€ versioning.py        # Manage model versioning
â”‚  â””â”€ config.py            # Pipeline configuration
â”œâ”€ tests/                  # Tests
â”‚  â”œâ”€ unit/                # Unit tests for functions and scripts
â”‚  â””â”€ integration/         # Integration tests for pipeline and API
â”œâ”€ Dockerfile              # Docker image definition
â”œâ”€ dvc.yaml                # DVC pipeline definition
â”œâ”€ requirements.txt        # Production dependencies
â”œâ”€ requirements-dev.txt    # Development dependencies
â”œâ”€ pytest.ini              # Pytest configuration
â”œâ”€ repo_structure.py       # Script to visualize repo structure
â””â”€ README.md               # Project documentation
```

---

## Installation

1. Clone the repository:

```bash
git clone https://github.com/LeonardoMdSACode/Automated-ML-Pipeline-CI-CD-Clean.git
cd Automated-ML-Pipeline-CI-CD-Clean
```

2. Create a virtual environment and install dependencies:

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.\.venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

3. Pull DVC data:

```bash
dvc pull
```

4. Run the FastAPI app locally:

```bash
uvicorn app.main:app --reload
```

---

## Usage

* **Train a model:** `python scripts/train.py`
* **Evaluate a model:** `python scripts/evaluate.py --model models/packaged/model.pkl`
* **Compare models and apply gates:** `python scripts/compare.py`
* **Package model for deployment:** `python scripts/package_model.py`

### Or run: `python scripts/bootstrap.py` instead.

* **Check API predictions:** Open `http://127.0.0.1:8000` in your browser

---

## Built With

* Python 3.10
* FastAPI
* scikit-learn
* GitHub Actions
* Pydantic

This project demonstrates a **reproducible, fully automated ML pipeline** with **enterprise-grade CI/CD practices**, suitable for real-world deployment and model governance.
