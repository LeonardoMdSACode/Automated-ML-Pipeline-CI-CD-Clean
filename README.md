---
title: Automated ML Pipeline with CI/CD
emoji: ðŸ¤–
colorFrom: gray
colorTo: red
sdk: docker
app_file: Dockerfile
pinned: false
license: mit
---

# Under Construction

# Notes

Raw dataset: https://www.kaggle.com/datasets/harlfoxem/housesalesprediction

py -3.10 -m venv .venv

.\\.venv\Scripts\activate

python -m pip install --upgrade pip

pip install -r requirements-dev.txt

python scripts/bootstrap.py

uvicorn app.main:app --reload

# Automated ML Pipeline with CI/CD

This repository contains a fully automated **Machine Learning pipeline** with **CI/CD capabilities**, designed for **house price prediction in King County, USA, 2015**. The project features reproducible model training, metric-based quality gates, versioned model packaging, and deployment-ready artifacts. It leverages **Python 3.10**, **scikit-learn** and **GitHub Actions** for automation, ensuring enterprise-grade reproducibility and governance.

The system is designed to run locally on venv python 3.10 or on Hugging Face Spaces, with minimal dependencies and a purposely simple front-end.

Hugging Face Space: [LeonardoMdSA / Automated ML Pipeline with CI/CD](https://huggingface.co/spaces/LeonardoMdSA/Automated-ML-Pipeline-with-CI-CD)

---

## Features

* **Automated Training & Evaluation:** Run training and evaluation pipelines with a single command.
* **Model Versioning:** Versioned models stored in a local registry (`models/registry`) with metadata.
* **Quality Gates:** Metric-based evaluation ensures only high-quality models are promoted.
* **Artifact Packaging:** Models packaged with metrics and metadata for reproducibility.
* **CI/CD Pipelines:** Fully automated using GitHub Actions for testing, evaluation, and deployment.
* **Web Interface:** Minimal FastAPI dashboard for predictions.

---

## Repository Structure (After running bootstrap.py)

```
Automated ML Pipeline with CI-CD/
â”œâ”€â”€ .github/
â”‚ â””â”€â”€ workflows/
â”‚ â”œâ”€â”€ deploy_hf.yml # Deploy inference app to Hugging Face Spaces
â”‚ â””â”€â”€ ml_pipeline.yml # CI pipeline: train, evaluate, gate, package
â”œâ”€â”€ .vscode/
â”‚ â””â”€â”€ settings.json # VS Code workspace settings
â”œâ”€â”€ app/ # Inference service (FastAPI)
â”‚ â”œâ”€â”€ api/
â”‚ â”‚ â””â”€â”€ routes.py # Prediction API routes
â”‚ â”œâ”€â”€ core/
â”‚ â”‚ â”œâ”€â”€ config.py # App configuration
â”‚ â”‚ â””â”€â”€ logging.py # Structured logging setup
â”‚ â”œâ”€â”€ inference/
â”‚ â”‚ â””â”€â”€ predictor.py # Loads *packaged* model and runs inference
â”‚ â”œâ”€â”€ schemas/
â”‚ â”‚ â””â”€â”€ request_response.py # Pydantic request/response schemas
â”‚ â”œâ”€â”€ static/
â”‚ â”‚ â””â”€â”€ styles.css # Frontend styles
â”‚ â”œâ”€â”€ templates/
â”‚ â”‚ â””â”€â”€ index.html # Minimal HTML frontend
â”‚ â””â”€â”€ main.py # FastAPI application entrypoint
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ kc_house_data.csv # Raw dataset
â”‚ â””â”€â”€ processed/
â”‚ â””â”€â”€ train_test.npz # Train/test split artifacts
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ baseline/
â”‚ â”‚ â””â”€â”€ metrics.json # Baseline model metrics
â”‚ â”œâ”€â”€ packaged/ # Production-ready model artifact
â”‚ â”‚ â”œâ”€â”€ model.pkl # Serialized best model
â”‚ â”‚ â”œâ”€â”€ metrics.json # Metrics of packaged model
â”‚ â”‚ â””â”€â”€ packaged.json # Packaging metadata
â”‚ â””â”€â”€ registry/ # Filesystem-based model registry
â”‚ â”œâ”€â”€ model_v001/
â”‚ â”‚ â”œâ”€â”€ model.pkl
â”‚ â”‚ â””â”€â”€ metadata.json
â”‚ â”œâ”€â”€ model_v002/
â”‚ â”‚ â”œâ”€â”€ model.pkl
â”‚ â”‚ â””â”€â”€ metadata.json
â”‚ â”œâ”€â”€ model_v003/
â”‚ â”‚ â”œâ”€â”€ model.pkl
â”‚ â”‚ â””â”€â”€ metadata.json
â”‚ â””â”€â”€ latest.json # Pointer to most recent trained model
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ evaluations/ # Per-run evaluation reports
â”‚ â”‚ â”œâ”€â”€ model_v001_run*.json
â”‚ â”‚ â”œâ”€â”€ model_v002_run*.json
â”‚ â”‚ â””â”€â”€ model_v003_run*.json
â”‚ â””â”€â”€ comparison.json # Model comparison results
â”œâ”€â”€ scripts/ # Pipeline execution scripts
â”‚ â”œâ”€â”€ bootstrap.py # End-to-end local bootstrap
â”‚ â”œâ”€â”€ train.py # Deterministic model training
â”‚ â”œâ”€â”€ evaluate.py # Model evaluation
â”‚ â”œâ”€â”€ compare.py # Compare candidate vs baseline
â”‚ â”œâ”€â”€ metric_gate.py # Quality gate enforcement
â”‚ â”œâ”€â”€ package_model.py # Package best model for inference
â”‚ â”œâ”€â”€ versioning.py # Model version increment logic
â”‚ â”œâ”€â”€ config.py # Pipeline configuration
â”‚ â””â”€â”€ __init__.py
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ integration/ # End-to-end and CI-like tests
â”‚ â”‚ â”œâ”€â”€ test_api_predict.py
â”‚ â”‚ â”œâ”€â”€ test_ci_like_flow.py
â”‚ â”‚ â”œâ”€â”€ test_gate_blocks_regression.py
â”‚ â”‚ â”œâ”€â”€ test_model_promotion.py
â”‚ â”‚ â””â”€â”€ test_train_evaluate_pipeline.py
â”‚ â”œâ”€â”€ unit/ # Deterministic unit tests
â”‚ â”‚ â”œâ”€â”€ test_compare_gate_logic.py
â”‚ â”‚ â”œâ”€â”€ test_compare_self_comparison_guard.py
â”‚ â”‚ â”œâ”€â”€ test_data_schema.py
â”‚ â”‚ â”œâ”€â”€ test_evaluate_deterministic.py
â”‚ â”‚ â”œâ”€â”€ test_metrics_computation.py
â”‚ â”‚ â”œâ”€â”€ test_metric_gate.py
â”‚ â”‚ â”œâ”€â”€ test_registry_metadata.py
â”‚ â”‚ â”œâ”€â”€ test_train_deterministic.py
â”‚ â”‚ â”œâ”€â”€ test_train_outputs.py
â”‚ â”‚ â””â”€â”€ test_version_increment.py
â”‚ â”œâ”€â”€ conftest.py
â”‚ â””â”€â”€ __init__.py
â”œâ”€â”€ Dockerfile # Container ready for Hugging Face Spaces
â”œâ”€â”€ pytest.ini # Pytest configuration
â”œâ”€â”€ requirements.txt # Runtime dependencies
â””â”€â”€ repo_structure.py # Utility to print repo tree
```

---

## Installation

1. Clone the repository:

```bash
git clone https://github.com/LeonardoMdSACode/Automated-ML-Pipeline-CI-CD-Clean.git
cd Automated-ML-Pipeline-CI-CD-Clean
```

2. Create a virtual environment and install dependencies:

```bash
py -3.10 -m venv .venv
source .venv/bin/activate  # Linux/Mac
.\.venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

---

## Usage

* **Train a model:** `python scripts/train.py`
* **Evaluate a model:** `python scripts/evaluate.py --model models/packaged/model.pkl`
* **Compare models and apply gates:** `python scripts/compare.py`
* **Package model for deployment:** `python scripts/package_model.py`

#### Or just run: `python scripts/bootstrap.py` instead.

1. Run the FastAPI app locally:

```bash
uvicorn app.main:app --reload
```

* **Check API predictions:** Open `http://127.0.0.1:8000` in your browser

---

## Testing

1. Run all tests with pytest:

   ```bash
   pytest -v
   ```

2. Tests will run regardless during CI at github actions.

---

## Technology Stack

* Python 3.10
* FastAPI
* Uvicorn
* scikit-learn
* GitHub Actions (CI/CD)
* Pydantic 2.12.5
* Jinja2
* Pandas / NumPy
* Joblib (for model serialization)
* Docker (for containerized deployment)
* Hugging Face Spaces (deployment)

This project demonstrates a **reproducible, fully automated ML pipeline** with **enterprise-grade CI/CD practices**, suitable for real-world deployment and model governance.


## MIT License

[![License](https://img.shields.io/badge/license-MIT-blue)](LICENSE)
